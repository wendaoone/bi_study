{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T12:03:19.390689Z",
     "start_time": "2020-11-09T12:03:14.808524Z"
    }
   },
   "source": [
    "# Thinking1:关联规则中的支持度、置信度和提升度代表的什么，如何计算\n",
    "\n",
    "    \n",
    "   |     | 概念  | 公式  |\n",
    "   |  ----  | ----  |  ----  |\n",
    "   | 支持度  | 商品在指定交易集合中出现的次数 |商品次数/总交易次数 |\n",
    "   | 置信度  | 在商品A出现的情况下，商品b出现的概率，也就是商品B在有商品A出现的交易中出现的次数 |  商品AB同时出现的次数/商品A出现的次数 |\n",
    "   | 提升度  | 商品A和商品B同时出现时候，商品B对商品A的支持程度 |支持度/置信度 |\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking2 关联规则与协同过滤的区别\n",
    "    \n",
    "     关联规则：是基于交易行为对物体固有的内部关系进行发掘，找出其频繁项集\n",
    "     协同过滤：是基于用户的历史行为习惯进行分析，挖掘用户喜好来进行推荐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking3 为什么我们需要多种推荐算法\n",
    "\n",
    "   各种推荐算法都有其优点以及适用场景，比如在电商系统中，对于一些冷启动的用户或这商品，可以通过关联规则方式进行前期推荐，等到有一定的用户行为或用户对商品的操作反馈信息后，可以使用协同过滤的方式推荐。通过关联规则可以发掘一些整体上的宏观规律性质的信息，协同过滤更具有个性化的需求\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking4 关联规则中的最小支持度、最小置信度该如何确定\n",
    " \n",
    " 通过经验数据来设置，比如交易数据量很大，此时每个商品在总商品中出现的次数都很低，如果设置的最小支持度或者最小置信度过大，则很可能筛选不出任何结果\n",
    " 也可以将每个商品的支持度，置信度计算出来，从大到小排序，然后卡定符合业务需求的位置所对应的指出度或置信度为最小支持度或者最小置信度\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking5  都有哪些常见的回归分析方法，评价指标是什么\n",
    "\n",
    "  常见的回归分析方法有：一元线性回归，多元线性回归 非线性回归\n",
    "  评价指标是通过损失函数来评价的，有mse(更容易收敛)  MAE(可解释性更强) RMSE(既收敛又兼具可解释性)  R方值\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action1  针对MarketBasket数据集进行购物篮分析（频繁项集及关联规则挖掘）[kaggle](https://www.kaggle.com/dragonheir/basket-optimisation)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T22:54:45.802167Z",
     "start_time": "2020-11-17T22:54:45.615004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   from                   to       sup      conf      lift\n",
      "52          (spaghetti)        (ground beef)  0.039195  0.225115  2.291162\n",
      "53        (ground beef)          (spaghetti)  0.039195  0.398915  2.291162\n",
      "67          (olive oil)          (spaghetti)  0.022930  0.348178  1.999758\n",
      "62               (soup)      (mineral water)  0.023064  0.456464  1.914955\n",
      "41               (milk)  (frozen vegetables)  0.023597  0.182099  1.910382\n",
      "40  (frozen vegetables)               (milk)  0.023597  0.247552  1.910382\n",
      "1             (burgers)               (eggs)  0.028796  0.330275  1.837830\n",
      "0                (eggs)            (burgers)  0.028796  0.160237  1.837830\n",
      "59          (olive oil)      (mineral water)  0.027596  0.419028  1.757904\n",
      "70           (tomatoes)          (spaghetti)  0.020931  0.306043  1.757755\n",
      "50      (mineral water)        (ground beef)  0.040928  0.171700  1.747522\n",
      "51        (ground beef)      (mineral water)  0.040928  0.416554  1.747522\n",
      "49        (ground beef)               (milk)  0.021997  0.223881  1.727704\n",
      "48               (milk)        (ground beef)  0.021997  0.169753  1.727704\n",
      "69             (shrimp)          (spaghetti)  0.021197  0.296642  1.703760\n",
      "43          (spaghetti)  (frozen vegetables)  0.027863  0.160031  1.678867\n",
      "44  (frozen vegetables)          (spaghetti)  0.027863  0.292308  1.678867\n",
      "20        (cooking oil)      (mineral water)  0.020131  0.394256  1.653978\n",
      "6             (chicken)      (mineral water)  0.022797  0.380000  1.594172\n",
      "42  (frozen vegetables)      (mineral water)  0.035729  0.374825  1.572463\n",
      "57          (spaghetti)               (milk)  0.035462  0.203675  1.571779\n",
      "58               (milk)          (spaghetti)  0.035462  0.273663  1.571779\n",
      "56               (milk)      (mineral water)  0.047994  0.370370  1.553774\n",
      "55      (mineral water)               (milk)  0.047994  0.201342  1.553774\n",
      "68           (pancakes)          (spaghetti)  0.025197  0.265077  1.522468\n",
      "15               (milk)          (chocolate)  0.032129  0.247942  1.513276\n",
      "14          (chocolate)               (milk)  0.032129  0.196094  1.513276\n",
      "65           (tomatoes)      (mineral water)  0.024397  0.356725  1.496530\n",
      "60           (pancakes)      (mineral water)  0.033729  0.354839  1.488616\n",
      "2             (burgers)       (french fries)  0.021997  0.252294  1.476173\n",
      "11  (frozen vegetables)          (chocolate)  0.022930  0.240559  1.468215\n",
      "66   (whole wheat rice)      (mineral water)  0.020131  0.343964  1.442993\n",
      "64          (spaghetti)      (mineral water)  0.059725  0.343032  1.439085\n",
      "63      (mineral water)          (spaghetti)  0.059725  0.250559  1.439085\n",
      "13        (ground beef)          (chocolate)  0.023064  0.234735  1.432669\n",
      "5                (cake)      (mineral water)  0.027463  0.338816  1.421397\n",
      "4             (burgers)          (spaghetti)  0.021464  0.246177  1.413918\n",
      "61             (shrimp)      (mineral water)  0.023597  0.330224  1.385352\n",
      "18          (spaghetti)          (chocolate)  0.039195  0.225115  1.373952\n",
      "19          (chocolate)          (spaghetti)  0.039195  0.239219  1.373952\n",
      "17          (chocolate)      (mineral water)  0.052660  0.321400  1.348332\n",
      "16      (mineral water)          (chocolate)  0.052660  0.220917  1.348332\n",
      "39    (frozen smoothie)      (mineral water)  0.020264  0.320000  1.342461\n",
      "26               (eggs)               (milk)  0.030796  0.171365  1.322437\n",
      "25               (milk)               (eggs)  0.030796  0.237654  1.322437\n",
      "54     (low fat yogurt)      (mineral water)  0.023997  0.313589  1.315565\n",
      "29           (pancakes)               (eggs)  0.021730  0.228612  1.272118\n",
      "23  (frozen vegetables)               (eggs)  0.021730  0.227972  1.268559\n",
      "33       (french fries)          (green tea)  0.028530  0.166927  1.263488\n",
      "32          (green tea)       (french fries)  0.028530  0.215943  1.263488\n",
      "36           (pancakes)       (french fries)  0.020131  0.211781  1.239135\n",
      "10       (french fries)          (chocolate)  0.034395  0.201248  1.228284\n",
      "9           (chocolate)       (french fries)  0.034395  0.209927  1.228284\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "通过mlxtend的apriori方式对数据进行分析\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import fptools as fp\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "# 读取数据\n",
    "datas=pd.read_csv('data/Market_Basket_Optimisation.csv',header=None)\n",
    "# 通过迭代器方式对pd读取出来的数据转成list数组，并且出去其中的nan\n",
    "itemsets = [[y for y in x if pd.notna(y)] for x in datas.values.tolist()]\n",
    "\n",
    "# 转换为算法可接受模型（布尔值）one-hot操作\n",
    "te = TransactionEncoder()\n",
    "df_tf = te.fit_transform(itemsets)\n",
    "df = pd.DataFrame(df_tf, columns=te.columns_)\n",
    "\n",
    "# 设置支持度求频繁项集\n",
    "frequent_itemsets = apriori(df, min_support=0.02, use_colnames=True)\n",
    "# 求关联规则,设置最小置信度为0.15\n",
    "rules = association_rules(frequent_itemsets,metric='confidence',  min_threshold=0.15)\n",
    "# 删除提升度小于1.2的关联项\n",
    "rules = rules.drop(rules[rules.lift < 1.2].index)\n",
    "# 对提升度由大到小排序\n",
    "rules = rules.sort_values(by=\"lift\",ascending=False) \n",
    "# # 设置标题索引并打印结果\n",
    "rules.rename(columns={'antecedents': 'from', 'consequents': 'to', 'support': 'sup', 'confidence': 'conf'}, inplace=True)\n",
    "rules = rules[['from', 'to', 'sup', 'conf', 'lift']]\n",
    "print(rules)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T23:04:05.696085Z",
     "start_time": "2020-11-17T23:04:03.140908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "条件模式基商品为：soup,对应的可推荐的[(('mineral water',), 173)]\n",
      "条件模式基商品为：cooking oil,对应的可推荐的[(('mineral water',), 151)]\n",
      "条件模式基商品为：whole wheat rice,对应的可推荐的[(('mineral water',), 151)]\n",
      "条件模式基商品为：chicken,对应的可推荐的[(('mineral water',), 171)]\n",
      "条件模式基商品为：frozen smoothie,对应的可推荐的[(('mineral water',), 152)]\n",
      "条件模式基商品为：olive oil,对应的可推荐的[(('spaghetti',), 172), (('mineral water',), 207)]\n",
      "条件模式基商品为：tomatoes,对应的可推荐的[(('spaghetti',), 157), (('mineral water',), 183)]\n",
      "条件模式基商品为：shrimp,对应的可推荐的[(('spaghetti',), 159), (('mineral water',), 177)]\n",
      "条件模式基商品为：low fat yogurt,对应的可推荐的[(('mineral water',), 180)]\n",
      "条件模式基商品为：cake,对应的可推荐的[(('mineral water',), 206)]\n",
      "条件模式基商品为：burgers,对应的可推荐的[(('french fries',), 165), (('spaghetti',), 161), (('eggs',), 216), (('mineral water',), 183)]\n",
      "条件模式基商品为：pancakes,对应的可推荐的[(('eggs',), 163), (('mineral water',), 253), (('french fries',), 151), (('spaghetti',), 189)]\n",
      "条件模式基商品为：frozen vegetables,对应的可推荐的[(('spaghetti',), 209), (('mineral water',), 268), (('milk',), 177), (('chocolate',), 172), (('eggs',), 163)]\n",
      "条件模式基商品为：ground beef,对应的可推荐的[(('chocolate',), 173), (('milk',), 165), (('spaghetti',), 294), (('mineral water',), 307)]\n",
      "条件模式基商品为：milk,对应的可推荐的[(('french fries',), 178), (('mineral water',), 360), (('chocolate',), 241), (('spaghetti',), 266), (('eggs',), 231)]\n",
      "条件模式基商品为：green tea,对应的可推荐的[(('chocolate',), 176), (('french fries',), 214), (('spaghetti',), 199), (('eggs',), 191), (('mineral water',), 233)]\n",
      "条件模式基商品为：chocolate,对应的可推荐的[(('mineral water',), 395), (('french fries',), 258), (('spaghetti',), 294), (('eggs',), 249)]\n",
      "条件模式基商品为：french fries,对应的可推荐的[(('spaghetti',), 207), (('eggs',), 273), (('mineral water',), 253)]\n",
      "条件模式基商品为：spaghetti,对应的可推荐的[(('mineral water',), 448), (('eggs',), 274)]\n",
      "条件模式基商品为：eggs,对应的可推荐的[(('mineral water',), 382)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import fptools as fp\n",
    "import collections\n",
    "\n",
    "# 读取数据\n",
    "# datas=pd.read_csv('./Market_Basket_Optimisation.csv',header=None)\n",
    "# # 通过迭代器方式对pd读取出来的数据转成list数组，并且出去其中的nan\n",
    "# itemsets = [[y for y in x if pd.notna(y)] for x in datas.values.tolist()]\n",
    "# itemDits = {}\n",
    "\n",
    "'''\n",
    "整体流程\n",
    "加载数据，并且对数据清洗，去除nan数据\n",
    "\n",
    "计算订单中每个商品出现的次数，以及最小支持度，并且对其由大到小排序\n",
    "\n",
    "根据最小支持度阈值获取符合条件的商品列表\n",
    "\n",
    "根据商品列表对每一个订单所对应的商品进行排序\n",
    "\n",
    "根据排序订单项构建fp-growth树\n",
    "\n",
    "从最后一个向上遍历得到条件模式基对应的平凡项集\n",
    "\n",
    "计算对应的支持度，置信度，提升度\n",
    "\n",
    "'''\n",
    "# 整体流程\n",
    "# 加载数据，并且对数据清洗，去除nan数据\n",
    "is_find_min_support = False\n",
    "\n",
    "\n",
    "def loadUseAbleData():\n",
    "    datas = pd.read_csv('data/Market_Basket_Optimisation.csv', header=None)\n",
    "    # 通过迭代器方式对pd读取出来的数据转成list数组，并且出去其中的nan\n",
    "    return [[y for y in x if pd.notna(y)] for x in datas.values.tolist()]\n",
    "\n",
    "\n",
    "def directItem(itemList, minSup, minItemCount):\n",
    "    \"\"\"\n",
    "    把商品标签化，并且映射为字典，然后计算订单中每个商品出现的次数，以及最小支持度，并且对其由大到小排序\n",
    "    :param itemList: 商品集\n",
    "    :param minSup: 最小支持度\n",
    "    :param minItemCount: 所需要的商品数量集合，用于根据业务筛选推荐的商品总数 当is_find_min_support=true时候 该项比较重要\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    itemDits = {}\n",
    "    # 遍历数组\n",
    "    for items in itemList:\n",
    "        for item in items:\n",
    "            if item not in itemDits.keys():\n",
    "                itemDits[item] = 1\n",
    "            else:\n",
    "                itemDits[item] = itemDits[item] + 1\n",
    "    # 当为获取最小支持度时候\n",
    "    if is_find_min_support:\n",
    "        itemDitsList = sorted(itemDits.items(), key=lambda item: item[1], reverse=True)[:minItemCount]\n",
    "        print('第{0}个商品所对应的支持度为{1},对应的商品出现的频次为：{2},总订单数{3}'.format(minItemCount, itemDitsList[-1][1] / len(itemList),\n",
    "                                                                  itemDitsList[-1][1], len(itemList)))\n",
    "        print(itemDitsList)\n",
    "        return dict(itemDitsList)\n",
    "    minCount = minSup * len(itemList)\n",
    "    itemDits = {k: v for k, v in itemDits.items() if v > minCount}\n",
    "    return sorted(itemDits.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "\n",
    "def sortedAndFiltter(itemList, orgItemList):\n",
    "    \"\"\"\n",
    "    对原始数据根据 itemsList排序，并将不存在于itemsList中对商品过滤掉\n",
    "    :param itemList:\n",
    "    :param itemsList: 目标商品列表\n",
    "    :param orgItemList: 原始订单所对应的商品列表\n",
    "    \"\"\"\n",
    "    itemSet = set(k[0] for k in itemList)\n",
    "    itemDict = dict(itemsList)\n",
    "    for index in range(len(orgItemList)):\n",
    "        orgItemList[index] = list(set(orgItemList[index]).intersection(itemSet))\n",
    "        orgItemList[index] = sorted(orgItemList[index], key=lambda s: itemDict[s], reverse=True)\n",
    "    return itemDict, orgItemList\n",
    "\n",
    "\n",
    "class FpNode(object):\n",
    "    def __init__(self, code, parent=None):\n",
    "        \"\"\"\n",
    "        树的基本结构单元\n",
    "        \"\"\"\n",
    "        self.code = code\n",
    "        self.child = collections.defaultdict()\n",
    "        self.parent = parent\n",
    "        # 说明是初始化的\n",
    "        if parent is None:\n",
    "            self.count = 0\n",
    "            return\n",
    "        self.count = 1\n",
    "        parent.child.setdefault(code, self)\n",
    "        return\n",
    "\n",
    "    def add_count(self):\n",
    "        self.count += 1\n",
    "        return\n",
    "\n",
    "\n",
    "class tree(object):\n",
    "    \"\"\"\n",
    "     构建的fp-growth有且只有一个根节点，元素值为None\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, itemDict, transaction_count):\n",
    "        self.transaction_count = transaction_count\n",
    "        self.root = FpNode(None, None)\n",
    "        # 用于快速检索到所有同一个code的所有树叶信息 格式为 code：[]\n",
    "        self.fpNodeDict = collections.defaultdict()\n",
    "        self.itemDict = itemDict\n",
    "        return\n",
    "\n",
    "    def insert_node(self, transaction_items):\n",
    "        \"\"\"\n",
    "        根据指定订单中的所有商品信息构建树的一条路径\n",
    "        \"\"\"\n",
    "        parent = self.root\n",
    "        for item in transaction_items:\n",
    "            code = item  # hash(item)\n",
    "            currentNode = parent.child.get(code)\n",
    "            # 如果当前节点为空说明该商品还没有加入关系树木中\n",
    "            if currentNode is None:\n",
    "                currentNode = FpNode(code, parent)\n",
    "                parent.child[code] = currentNode\n",
    "                codeItems = self.fpNodeDict.get(code, [])\n",
    "                codeItems.append(currentNode)\n",
    "                self.fpNodeDict.setdefault(code, codeItems)\n",
    "                parent = currentNode\n",
    "                continue\n",
    "                # 当前节点已经存在，直接对节点数量加一\n",
    "            currentNode.add_count()\n",
    "            parent = currentNode\n",
    "        return self\n",
    "\n",
    "    def build_tree(self, transaction):\n",
    "        \"\"\"\n",
    "        根据所有订单构建树\n",
    "        \"\"\"\n",
    "        for item in transaction:\n",
    "            self.insert_node(item)\n",
    "        return self\n",
    "\n",
    "    def condition_merge(self, conditionList):\n",
    "        \"\"\"\n",
    "        通过递归方式对同一条链路上的商品合并，获取其上所有可组合的频繁项集\n",
    "        :param conditionList:链路上的所有商品\n",
    "        :return: [(集合:count),(集合:count)]\n",
    "        conditionList 中只有一个元素时候 则表示已经把所有情况组合完成\n",
    "        \"\"\"\n",
    "        if len(conditionList) <= 1:\n",
    "            return conditionList\n",
    "        mergedConditionList = []\n",
    "        for conditionItemIndex in range(len(conditionList)):\n",
    "            conditionItem = conditionList[conditionItemIndex]\n",
    "            groupConditionList = []\n",
    "            for item in conditionList[conditionItemIndex+1:]:\n",
    "                itemSet = set(item[0])\n",
    "                itemSet.update(conditionItem[0])\n",
    "                groupConditionList.append((itemSet, conditionItem[1]))\n",
    "            # 对于同一层采用递归调用方式如\n",
    "            #         A B C D E\n",
    "            #           合成 AB AC AD AE后把它当作一个整体 做输入条件\n",
    "            if len(groupConditionList) == 0:\n",
    "                continue\n",
    "            mergedConditionList.extend(self.condition_merge(groupConditionList))\n",
    "        conditionList.extend(mergedConditionList)\n",
    "        return conditionList\n",
    "\n",
    "    def condition_frequent_item(self, conditionNodeList, comdition_item_count,min_threshold = 0):\n",
    "        \"\"\"\n",
    "        对同一个商品的所有路径进行组合，得到条件模式基的频繁项集以及对应频次，并把各个路径的相同的平凡项集合并为同一个，数量叠加一起\n",
    "        :param conditionNodeList: 同一个商品的所有路径列表\n",
    "        :param min_threshold: 最小阈值\n",
    "        \"\"\"\n",
    "        allConditionNodeList = []\n",
    "        # 对不同路径上的商品进行组合，得到频繁项集\n",
    "        for node in conditionNodeList:\n",
    "            count = node.count\n",
    "            parent = node.parent\n",
    "            conditionList = []\n",
    "            while parent.code is not None:\n",
    "                code = parent.code\n",
    "                conditionList.append(({code}, count))\n",
    "                parent = parent.parent\n",
    "            # 对 conditionList 进行自由组合 先从k=2开始组合\n",
    "            allConditionNodeList.extend(self.condition_merge(conditionList))\n",
    "        item_dict = {}\n",
    "        for item in allConditionNodeList:\n",
    "            item_tuple = tuple(item[0]);\n",
    "            count = item_dict.pop(item_tuple, 0) + item[1]\n",
    "            item_dict.setdefault(item_tuple, count)\n",
    "\n",
    "        return [(k,v) for k, v in item_dict.items() if v >= min_threshold]\n",
    "\n",
    "    def frequent_item_sets(self, items_list, min_sup=None):\n",
    "        \"\"\"\n",
    "         获取条件基的频繁项集\n",
    "         从排序最后的叶子作为条件模式基 向上获取条件频繁项集,\n",
    "         然后根据最小支持度预集合得到最终频繁项集\n",
    "        \"\"\"\n",
    "        minCount = min_sup * self.transaction_count\n",
    "        for item in reversed(items_list):\n",
    "            result = self.condition_frequent_item(self.fpNodeDict.get(item[0]),item[1], minCount)\n",
    "            if len(result) > 0:\n",
    "                print(\"条件模式基商品为：{},对应的可推荐的{}\".format(item[0],result))\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    is_find_min_support = False\n",
    "    orgItemList = loadUseAbleData()\n",
    "    itemsList = directItem(orgItemList, 0.02, 100)\n",
    "    itemDict, orgItemList = sortedAndFiltter(itemsList, orgItemList)\n",
    "    tree(itemDict, len(orgItemList)).build_tree(orgItemList).frequent_item_sets(itemsList, 0.02)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结论：通过ml方法的结果中可以看到支持度高的，置信度不一定高，置信度高的 提升度不一定高，它的可以使用三个指标灵活切换，而fp-growth一次只能根据一个指标来计算，但是fp-growth在内存使用量上确实比ml方式的要小很多，因为在前期数据处理阶段就可以通过指标把大量数据给过滤掉，同时树结构也大大节省了内存空间，所以fp-growth适合处理大数据量处理，而小数据量的话使用ml会更好一些，指标丰富，灵活\n",
    "\n",
    "疑问：超市中一个订单中只包含一个商品的应该占大多数，那么如果筛选出来的前一百个商品正好都是单订单商品，fp-growthß是否无法完成推荐呢？\n",
    "  助教解答：首先可以在数据预处理部分对这部分数据进行处理，并且这部分数据其实也是很有统计意义的，可以结合用户特性进行分析，代表购买这部分商品的用户倾向于比较具有针对性地进行购物，此外，这部分数据也可以代表这类物品的全局属性，比如需求程度、物品使用或被购买的独立程度等等\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
