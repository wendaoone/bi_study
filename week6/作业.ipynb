{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TINKING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T14:12:17.670383Z",
     "start_time": "2020-12-05T14:12:17.665885Z"
    }
   },
   "source": [
    "## 在实际工作中，FM和MF哪个应用的更多，为什么(1、能简要说明FM和MF的区别 2、能简要说明FM在推荐系统，以及应用场景中的作用)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MF主要采用svd方式或者asl方式对矩阵进行分解，它只能分解成为两个矩阵和一个特征矩阵的乘积，分别是user矩阵和item矩阵与特征矩阵，通过交替二乘 法或者梯度向量来得到这三个矩阵。\n",
    "FM是从线性模型中通过增加二阶交叉项来拟合特征之间的交叉，可以分解高阶特征，是一种更加泛化的矩阵分解方式，可以将MF模型看作是FM模型的特例。\n",
    "\n",
    "FM在推荐系统中可以挖掘出更多高纬度特征，通过简单纬度特征交叉获得更加复杂特征，如通过中国、年龄、女性 可以挖掘出中国大妈这种特征群体从而提升模型效果。通过这种特征可以用来评估站内的CTR和CVR，即一个用户对一个商品的潜在点击率和点击后的转化率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFM与FM有哪些区别？(能简要说明区别)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FM：是解决稀疏数据下的特征组合问题，具有线性的计算复杂度；（矩阵分解方式处理参数，不仅能减少参数数量，还能处理由于稀疏性带来的参数不好训练的问题）一般的线性模型压根没有考虑特征间的关联(组合)。为了表述特征间的相关性，我们采用多项式模型。观察大量的样本数据可以发现，某些特征经过关联之后，与label之间的相关性就会提高\n",
    "\n",
    "FFM：通过引入field的概念，FFM把相同性质的特征归于同一个field，同一个categorical特征经过One-Hot编码生成的数值特征都可以放到同一个field，包括用户性别、职业、品类偏好等。在FFM中，每一维特征 xi，针对其它特征的每一种field fj，都会学习一个隐向量 vi,fj。因此，隐向量不仅与特征相关，也与field相关，当filed=1时候，FFM就退化为FM了\n",
    "\n",
    "FFM的计算时间复杂度比FM更大，但是也更加精确\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepFM相比于FM解决了哪些问题，原理是怎样的(1、能说明DeepFM相比于FM有哪些改进的地方2、能说明DeepFM的原理，FM+DNN模型)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FM通过对于每一位特征的隐变量内积来提取特征组合，最后的结果也不错，虽然理论上FM可以对高阶特征组合进行建模，但实际上因为计算复杂度原因，一般都只用到了二阶特征组合。对于高阶特征组合来说，一般会使用多层神经网络DNN。\n",
    "\n",
    "DeepFM目的是同时学习低阶和高阶的特征交叉，主要由FM和DNN两部分组成，底部共享同样的输入。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surprise工具中的baseline算法原理是怎样的？BaselineOnly和KNNBaseline有什么区别？(1、能简要说明baseline的原理 2、能简要说明BaselineOnly和KNNBaseline的区别)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline算法是基于统计的基准预测线打分，bui 预测值 bu 用户对整体的偏差 bi 商品对整体的偏差，它是通过最小二乘法来计算的，先固定bu来优化bi，然后在固定bi，优化bu（这两个过程是可以并行的）\n",
    "KNNBaseline 是考虑基线评级的协同过滤，利用行为的相似度计算用户的相似度\n",
    "BaselineOnly 是以评分基数为基础的打分，它综合了用户和item的历史打分情况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 基于邻域的协同过滤都有哪些算法，请简述原理 (1、能说出两种不同的基于邻域的协同过滤的算法  2、这些算法之间的区别和作用)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNNBasic 是基础的协同过滤，通过它可以计算用户与用户之间的相似性或者物品与物品之间的相似性\n",
    "\n",
    "KNNWithMeans基本的假设是用户和物品的评分有高低，考虑了每个用户打分均值或者每个item打分的均值，去除参考用户打分整体偏高和偏低的影响\n",
    "\n",
    "KNNBaseline是对KNNWithMeans的改进，采用baseline均值来替代均值\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用libfm工具对movielens进行评分预测，采用SGD优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T05:23:39.671181Z",
     "start_time": "2020-12-18T05:13:42.393662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/deepctr/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/deepctr/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f97c94fdeb0>, 'Connection to pypi.org timed out. (connect timeout=15)')': /simple/deepctr/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f97c95079d0>, 'Connection to pypi.org timed out. (connect timeout=15)')': /simple/deepctr/\u001b[0m\n",
      "Requirement already up-to-date: deepctr in /Users/hui/opt/anaconda3/lib/python3.8/site-packages (0.8.2)\n",
      "Requirement already satisfied, skipping upgrade: requests in /Users/hui/opt/anaconda3/lib/python3.8/site-packages (from deepctr) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /Users/hui/opt/anaconda3/lib/python3.8/site-packages (from deepctr) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /Users/hui/opt/anaconda3/lib/python3.8/site-packages (from requests->deepctr) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/hui/opt/anaconda3/lib/python3.8/site-packages (from requests->deepctr) (1.25.10)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /Users/hui/opt/anaconda3/lib/python3.8/site-packages (from requests->deepctr) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /Users/hui/opt/anaconda3/lib/python3.8/site-packages (from requests->deepctr) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: six in /Users/hui/opt/anaconda3/lib/python3.8/site-packages (from h5py->deepctr) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.7 in /Users/hui/opt/anaconda3/lib/python3.8/site-packages (from h5py->deepctr) (1.19.4)\n"
     ]
    }
   ],
   "source": [
    "# perl ./code/libfm/triple_format_to_libfm.pl -in ./titanic/test.csv -target 1 -delete_column 0 -separator \"::\"\n",
    "!pip install -U deepctr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用DeepFM对movielens进行评分预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T12:13:35.331813Z",
     "start_time": "2020-12-18T12:13:35.316281Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SparseFeat' from 'deepctr.inputs' (/Users/hui/opt/anaconda3/lib/python3.8/site-packages/deepctr/inputs.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a41f7d8a4380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepctr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeepFM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepctr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparseFeat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#数据加载\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'SparseFeat' from 'deepctr.inputs' (/Users/hui/opt/anaconda3/lib/python3.8/site-packages/deepctr/inputs.py)"
     ]
    }
   ],
   "source": [
    "#!pip install deepctr\n",
    "# !pip install tensorflow\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from deepctr.models import DeepFM\n",
    "from deepctr.inputs import SparseFeat,get_feature_names\n",
    "\n",
    "#数据加载\n",
    "\n",
    "data = pd.read_csv(\"./code/deepfm/movielens_sample.txt\")\n",
    "sparse_features = [\"movie_id\", \"user_id\", \"gender\", \"age\", \"occupation\", \"zip\"]\n",
    "target = ['rating']\n",
    "\n",
    "# 对特征标签进行编码\n",
    "for feature in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feature] = lbe.fit_transform(data[feature])\n",
    "# 计算每个特征中的 不同特征值的个数\n",
    "fixlen_feature_columns = [SparseFeat(feature, data[feature].nunique()) for feature in sparse_features]\n",
    "print(fixlen_feature_columns)\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "# 将数据集切分成训练集和测试集\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train_model_input = {name:train[name].values for name in feature_names}\n",
    "test_model_input = {name:test[name].values for name in feature_names}\n",
    "\n",
    "# 使用DeepFM进行训练\n",
    "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression')\n",
    "model.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = model.fit(train_model_input, train[target].values, batch_size=256, epochs=1, verbose=True, validation_split=0.2, )\n",
    "# 使用DeepFM进行预测\n",
    "pred_ans = model.predict(test_model_input, batch_size=256)\n",
    "# 输出RMSE或MSE\n",
    "mse = round(mean_squared_error(test[target].values, pred_ans), 4)\n",
    "rmse = mse ** 0.5\n",
    "print(\"test RMSE\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用基于邻域的协同过滤（KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline中的任意一种）对MovieLens数据集进行协同过滤，采用k折交叉验证(k=3)，输出每次计算的RMSE, MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T12:09:35.185581Z",
     "start_time": "2020-12-18T12:04:07.038074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "           第一次       第二次       第三次        均值\n",
      "rmse  0.858293  0.855608  0.855494  0.856465\n",
      "mae   0.655689  0.654485  0.654445  0.654873\n"
     ]
    }
   ],
   "source": [
    "## KNNWithMeans 方式\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import Dataset, Reader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import KFold\n",
    "\n",
    "# 数据读取\n",
    "reader = Reader(line_format='user item rating timestamp', sep=',', skip_lines=1)\n",
    "data = Dataset.load_from_file('./code/knn_cf/ratings.csv', reader=reader)\n",
    "\n",
    "# ItemCF 计算得分\n",
    "# 取最相似的用户计算时，只取最相似的k个\n",
    "algo = KNNWithMeans(k=50, sim_options={'user_based': False, 'verbose': 'True'})\n",
    "resme=[]\n",
    "mae=[]\n",
    "kf = KFold(n_splits=3)\n",
    "for trainset, testset in kf.split(data):\n",
    "    # 训练并预测\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    # 计算RMSE\n",
    "    resme.append(accuracy.rmse(predictions, verbose=False))\n",
    "    mae.append(accuracy.mae(predictions, verbose=False))\n",
    "    uid = str(196)\n",
    "    iid = str(302)\n",
    "    pred = algo.predict(uid, iid)\n",
    "\n",
    "resme.append(np.mean(resme))\n",
    "mae.append(np.mean(mae))\n",
    "pd=pd.DataFrame(np.array([resme,mae]),index=['rmse','mae'],columns=['第一次','第二次','第三次','均值'])\n",
    "print(pd) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
